{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Tweet Sentiment Predictor\n",
    "\n",
    "Lately, cryptocurrencies have become very popular on the internet. People increasingly find clever ways to move with the market and make quick money by trading one cryptocurrency with the other. However, Bitcoin, the original cryptocurrency, still stands on top and boasts a strong position.\n",
    "\n",
    "However, Bitcoin followers aren't usually seen in that light and are blamed for being toxic and voicing negative opinions on the internet. This project will build a model that will predict the sentiment of a Bitcoin tweet.\n",
    "\n",
    "First, we will import all the necessary libraries that'll be used in the context of this project to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import utils\n",
    "\n",
    "# Natural Language Processing imports\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Scikit learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset Into Memory\n",
    "\n",
    "We will first load the dataset int memory and showcase the results. As you can see from the example below, there are quite a number of columns and unnecessary features that we need to remove. This will become a hinderance to the model and will bring unexpected results so we need to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen_name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Link</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>New_Sentiment_Score</th>\n",
       "      <th>New_Sentiment_State</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Mar 23 00:40:32 +0000 2018</td>\n",
       "      <td>RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I h...</td>\n",
       "      <td>myresumerocket</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri Mar 23 00:40:34 +0000 2018</td>\n",
       "      <td>@lopp @_Kevin_Pham @psycho_sage @naval But @Pr...</td>\n",
       "      <td>BitMocro</td>\n",
       "      <td>[u'Bitcoin']</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fri Mar 23 00:40:35 +0000 2018</td>\n",
       "      <td>RT @tippereconomy: Another use case for #block...</td>\n",
       "      <td>hojachotopur</td>\n",
       "      <td>[u'blockchain', u'Tipper', u'TipperEconomy']</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136363636363636</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fri Mar 23 00:40:36 +0000 2018</td>\n",
       "      <td>free coins https://t.co/DiuoePJdap</td>\n",
       "      <td>denies_distro</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fri Mar 23 00:40:36 +0000 2018</td>\n",
       "      <td>RT @payvxofficial: WE are happy to announce th...</td>\n",
       "      <td>aditzgraha</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468181818181818</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50882</th>\n",
       "      <td>50854</td>\n",
       "      <td>Fri Mar 23 08:55:16 +0000 2018</td>\n",
       "      <td>RT @fixy_app: Fixy Network brings popular cryp...</td>\n",
       "      <td>quoting_lives</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50883</th>\n",
       "      <td>50855</td>\n",
       "      <td>Fri Mar 23 08:55:17 +0000 2018</td>\n",
       "      <td>RT @bethereumteam: After a successful launch o...</td>\n",
       "      <td>VariPewitt</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50884</th>\n",
       "      <td>50856</td>\n",
       "      <td>Fri Mar 23 08:55:18 +0000 2018</td>\n",
       "      <td>RT @GymRewards: Buy #GYMRewards Tokens, Bonus ...</td>\n",
       "      <td>urbancoinerz</td>\n",
       "      <td>[u'GYMRewards', u'ICO', u'cryptocurrency', u'm...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50885</th>\n",
       "      <td>50857</td>\n",
       "      <td>Fri Mar 23 08:55:19 +0000 2018</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>MRDanishShahab</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://www.google.com/\" rel=\"nofollow...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50886</th>\n",
       "      <td>50858</td>\n",
       "      <td>Fri Mar 23 08:55:19 +0000 2018</td>\n",
       "      <td>RT @Raybambs: Airdrop PhotoCoin Airdrop Round#...</td>\n",
       "      <td>Azriel020</td>\n",
       "      <td>[u'PhotoCoin']</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50887 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                            Date  \\\n",
       "0              0  Fri Mar 23 00:40:32 +0000 2018   \n",
       "1              1  Fri Mar 23 00:40:34 +0000 2018   \n",
       "2              2  Fri Mar 23 00:40:35 +0000 2018   \n",
       "3              3  Fri Mar 23 00:40:36 +0000 2018   \n",
       "4              4  Fri Mar 23 00:40:36 +0000 2018   \n",
       "...          ...                             ...   \n",
       "50882      50854  Fri Mar 23 08:55:16 +0000 2018   \n",
       "50883      50855  Fri Mar 23 08:55:17 +0000 2018   \n",
       "50884      50856  Fri Mar 23 08:55:18 +0000 2018   \n",
       "50885      50857  Fri Mar 23 08:55:19 +0000 2018   \n",
       "50886      50858  Fri Mar 23 08:55:19 +0000 2018   \n",
       "\n",
       "                                                   Tweet     Screen_name  \\\n",
       "0      RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I h...  myresumerocket   \n",
       "1      @lopp @_Kevin_Pham @psycho_sage @naval But @Pr...        BitMocro   \n",
       "2      RT @tippereconomy: Another use case for #block...    hojachotopur   \n",
       "3                     free coins https://t.co/DiuoePJdap   denies_distro   \n",
       "4      RT @payvxofficial: WE are happy to announce th...      aditzgraha   \n",
       "...                                                  ...             ...   \n",
       "50882  RT @fixy_app: Fixy Network brings popular cryp...   quoting_lives   \n",
       "50883  RT @bethereumteam: After a successful launch o...      VariPewitt   \n",
       "50884  RT @GymRewards: Buy #GYMRewards Tokens, Bonus ...    urbancoinerz   \n",
       "50885  I added a video to a @YouTube playlist https:/...  MRDanishShahab   \n",
       "50886  RT @Raybambs: Airdrop PhotoCoin Airdrop Round#...       Azriel020   \n",
       "\n",
       "                                                  Source  \\\n",
       "0                                                     []   \n",
       "1                                           [u'Bitcoin']   \n",
       "2           [u'blockchain', u'Tipper', u'TipperEconomy']   \n",
       "3                                                     []   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "50882                                                 []   \n",
       "50883                                                 []   \n",
       "50884  [u'GYMRewards', u'ICO', u'cryptocurrency', u'm...   \n",
       "50885                                                 []   \n",
       "50886                                     [u'PhotoCoin']   \n",
       "\n",
       "                                                    Link     Sentiment  \\\n",
       "0      <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   ['neutral']   \n",
       "1      <a href=\"http://twitter.com/download/android\" ...   ['neutral']   \n",
       "2      <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ['positive']   \n",
       "3      <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ['positive']   \n",
       "4      <a href=\"http://twitter.com/download/android\" ...  ['positive']   \n",
       "...                                                  ...           ...   \n",
       "50882  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ['positive']   \n",
       "50883  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ['positive']   \n",
       "50884  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   ['neutral']   \n",
       "50885  <a href=\"http://www.google.com/\" rel=\"nofollow...  ['positive']   \n",
       "50886  <a href=\"http://twitter.com/download/android\" ...  ['positive']   \n",
       "\n",
       "      sent_score New_Sentiment_Score New_Sentiment_State Unnamed: 10  \\\n",
       "0              0                   0                   0         NaN   \n",
       "1              0                   0                   0         NaN   \n",
       "2              1   0.136363636363636                   1         NaN   \n",
       "3              1                 0.4                   1         NaN   \n",
       "4              1   0.468181818181818                   1         NaN   \n",
       "...          ...                 ...                 ...         ...   \n",
       "50882          1                 0.6                   1         NaN   \n",
       "50883          1               0.375                   1         NaN   \n",
       "50884          0                   0                   0         NaN   \n",
       "50885          1                 0.4                   1         NaN   \n",
       "50886          1               -0.05                  -1         NaN   \n",
       "\n",
       "      Unnamed: 11 Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0             NaN         NaN          NaN          NaN          NaN  \n",
       "1             NaN         NaN          NaN          NaN          NaN  \n",
       "2             NaN         NaN          NaN          NaN          NaN  \n",
       "3             NaN         NaN          NaN          NaN          NaN  \n",
       "4             NaN         NaN          NaN          NaN          NaN  \n",
       "...           ...         ...          ...          ...          ...  \n",
       "50882         NaN         NaN          NaN          NaN          NaN  \n",
       "50883         NaN         NaN          NaN          NaN          NaN  \n",
       "50884         NaN         NaN          NaN          NaN          NaN  \n",
       "50885         NaN         NaN          NaN          NaN          NaN  \n",
       "50886         NaN         NaN          NaN          NaN          NaN  \n",
       "\n",
       "[50887 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDataset = pd.read_csv(\"BTC_tweets_daily_example.csv\", low_memory=False)\n",
    "fullDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Dataset\n",
    "\n",
    "We now have to clean the dataset to proceed with the project. Following things are at fault with the original dataset:\n",
    "\n",
    " - There are a unnecessary amount of features\n",
    " - There are some null values far into the dataset\n",
    " - There are invalid values in the \"Sentiment\" column, which should only accept \"positive\", \"neutral\" and \"negative\"\n",
    " - The sentiment column stores sentiment strings as stringified lists. We need to change that\n",
    "\n",
    "<br>\n",
    "\n",
    "The following changes will be made:\n",
    "\n",
    " - All columns except \"Tweet\" and \"Sentiment\" will be dropped.\n",
    " - Null values will be dropped\n",
    " - Sentiment values will be converted from stringified lists to simple strings e.g. ['positive'] => positive\n",
    " - Unknown values from \"Sentiment\" column will be deleted\n",
    " - Cleaned dataset will be saved as cleaned_btc_tweets.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning the sentiment column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I had to tweak the nose of this Bitcoin enemy. He says such foolish things. Here's the link: htt…</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@lopp @_Kevin_Pham @psycho_sage @naval But @ProfFaustus (dum b a ss) said you know nothing about #Bitcoin ... 😂😂😂 https://t.co/SBAMFQ2Yiy</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @tippereconomy: Another use case for #blockchain and #Tipper. The #TipperEconomy  can unseat Facebook and change everything! ICO Live No…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free coins https://t.co/DiuoePJdap</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @payvxofficial: WE are happy to announce that PayVX Presale Phase 1 is now LIVE!\\n\\nSign up --&amp;gt;&amp;gt; https://t.co/dhprzsSxek\\nCurrencies accept…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50882</th>\n",
       "      <td>RT @fixy_app: Fixy Network brings popular cryptocurrencies and retailers as partners with benefits from blockchain. Partner Stores will acc…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50883</th>\n",
       "      <td>RT @bethereumteam: After a successful launch of our Bounty campaign, we've managed to filter out the Bounty related questions to: https://t…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50884</th>\n",
       "      <td>RT @GymRewards: Buy #GYMRewards Tokens, Bonus Time is ending! https://t.co/HDvhoZrz2J, #ICO #cryptocurrency #mobile #app #mining #exercisin…</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50885</th>\n",
       "      <td>I added a video to a @YouTube playlist https://t.co/ntFJrNvSvZ How To Bitcoin Cloud Mining Free For Lifetime Urdu / Hindi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50886</th>\n",
       "      <td>RT @Raybambs: Airdrop PhotoCoin Airdrop Round#2. 100 #PhotoCoin will be giving to everyone who complete the google form. Your account will…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49751 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                       Tweet  \\\n",
       "0               RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I had to tweak the nose of this Bitcoin enemy. He says such foolish things. Here's the link: htt…   \n",
       "1                  @lopp @_Kevin_Pham @psycho_sage @naval But @ProfFaustus (dum b a ss) said you know nothing about #Bitcoin ... 😂😂😂 https://t.co/SBAMFQ2Yiy   \n",
       "2               RT @tippereconomy: Another use case for #blockchain and #Tipper. The #TipperEconomy  can unseat Facebook and change everything! ICO Live No…   \n",
       "3                                                                                                                         free coins https://t.co/DiuoePJdap   \n",
       "4      RT @payvxofficial: WE are happy to announce that PayVX Presale Phase 1 is now LIVE!\\n\\nSign up --&gt;&gt; https://t.co/dhprzsSxek\\nCurrencies accept…   \n",
       "...                                                                                                                                                      ...   \n",
       "50882           RT @fixy_app: Fixy Network brings popular cryptocurrencies and retailers as partners with benefits from blockchain. Partner Stores will acc…   \n",
       "50883           RT @bethereumteam: After a successful launch of our Bounty campaign, we've managed to filter out the Bounty related questions to: https://t…   \n",
       "50884           RT @GymRewards: Buy #GYMRewards Tokens, Bonus Time is ending! https://t.co/HDvhoZrz2J, #ICO #cryptocurrency #mobile #app #mining #exercisin…   \n",
       "50885                              I added a video to a @YouTube playlist https://t.co/ntFJrNvSvZ How To Bitcoin Cloud Mining Free For Lifetime Urdu / Hindi   \n",
       "50886            RT @Raybambs: Airdrop PhotoCoin Airdrop Round#2. 100 #PhotoCoin will be giving to everyone who complete the google form. Your account will…   \n",
       "\n",
       "      Sentiment  \n",
       "0       neutral  \n",
       "1       neutral  \n",
       "2      positive  \n",
       "3      positive  \n",
       "4      positive  \n",
       "...         ...  \n",
       "50882  positive  \n",
       "50883  positive  \n",
       "50884   neutral  \n",
       "50885  positive  \n",
       "50886  positive  \n",
       "\n",
       "[49751 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all unneeded columns except tweet and sentiment colums\n",
    "btc_tweets = fullDataset.drop(fullDataset.columns[[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15]], axis=1)\n",
    "\n",
    "btc_tweets = btc_tweets.dropna()\n",
    "# btc_tweets = btc_tweets.head(10000)\n",
    "\n",
    "indices = []\n",
    "\n",
    "# This loop clears all sentiment values that aren't known\n",
    "for index, row in btc_tweets.iterrows():\n",
    "    \n",
    "    sentiment = btc_tweets['Sentiment'][index].strip('][\\'')\n",
    "    \n",
    "    if sentiment == \"positive\":\n",
    "        btc_tweets.loc[index, 'Sentiment'] = sentiment\n",
    "        continue\n",
    "    if sentiment == \"neutral\":\n",
    "        btc_tweets.loc[index, 'Sentiment'] = sentiment\n",
    "        continue\n",
    "    if sentiment == \"negative\":\n",
    "        btc_tweets.loc[index, 'Sentiment'] = sentiment\n",
    "        continue\n",
    "        \n",
    "    indices.append(index)\n",
    "    \n",
    "btc_tweets = btc_tweets.drop(labels=indices, axis=0)\n",
    "\n",
    "btc_tweets.to_csv(r'cleaned_btc_tweets.csv', index = False)\n",
    "\n",
    "print(\"After cleaning the sentiment column:\")\n",
    "pd.options.display.max_colwidth = 200\n",
    "btc_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Balance of Sentiments in Dataset\n",
    "\n",
    "As we can see above, we have 50,886 total instances in the dataset even after cleaning. Now we check the balance of ratios between the instances with respect to sentiment so we have around equal of each sentiment. This step is crucial to designing a good data model. We have to check the ratio at which our tweets are divided by sentiment into the dataset.\n",
    "\n",
    "This is important because if one of the sentiments is less in number with respect to the others, the model may get trained on inaccurate data and, hence, provide inaccurate results\n",
    "\n",
    "The following loop will count all sentiment instances in the cleaned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Tweets: 22656\n",
      "Neutral Tweets: 21150\n",
      "Negative Tweets: 5945\n"
     ]
    }
   ],
   "source": [
    "positiveCount = 0\n",
    "neutralCount = 0\n",
    "negativeCount = 0\n",
    "\n",
    "for index, row in btc_tweets.iterrows():\n",
    "    sentiment = btc_tweets['Sentiment'][index].strip('][\\'')\n",
    "    \n",
    "    if sentiment == \"positive\":\n",
    "        positiveCount += 1\n",
    "        \n",
    "    if sentiment == \"neutral\":\n",
    "        neutralCount += 1\n",
    "        \n",
    "    if sentiment == \"negative\":\n",
    "        negativeCount += 1\n",
    "        \n",
    "print(\"Positive Tweets:\", positiveCount)\n",
    "print(\"Neutral Tweets:\", neutralCount)\n",
    "print(\"Negative Tweets:\", negativeCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is Unbalanced\n",
    "\n",
    "As we can see, negative sentiment tweets are almost 4 times lower than positive and neutral sentiments. This will affect the prediction results of the model if we train it on unbalanced data.\n",
    "\n",
    "For this reason, we will cut down positive and neutral tweets until they match exactly the negative tweets' number and then proceed to the next step. The following loop does exactly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I had to tweak the nose of this Bitcoin enemy. He says such foolish things. Here's the link: htt…</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@lopp @_Kevin_Pham @psycho_sage @naval But @ProfFaustus (dum b a ss) said you know nothing about #Bitcoin ... 😂😂😂 https://t.co/SBAMFQ2Yiy</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @tippereconomy: Another use case for #blockchain and #Tipper. The #TipperEconomy  can unseat Facebook and change everything! ICO Live No…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free coins https://t.co/DiuoePJdap</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @payvxofficial: WE are happy to announce that PayVX Presale Phase 1 is now LIVE!\\n\\nSign up --&amp;gt;&amp;gt; https://t.co/dhprzsSxek\\nCurrencies accept…</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17830</th>\n",
       "      <td>RT @PumaPay: Why Did Credit Cards Fail to Adopt to the Modern Needs? https://t.co/u1qB3gxA3T #pumapay #creditcards #banking #finance #block…</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17831</th>\n",
       "      <td>Bitcoin Will Be World's 'Single Currency' Says Twitter CEO https://t.co/f4hsEbLgkk https://t.co/P3fuHSLwkX</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17832</th>\n",
       "      <td>RT @CloudMiningX: Use the code: HF18BDAY30 at purchase to get a 30% discount for all contracts. The offer is limited. \\n\\n10 Ghs = 0.84$\\n1000…</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17833</th>\n",
       "      <td>Twitter CEO Says Bitcoin Will Be World’s ‘Single Currency’ Within A Decade https://t.co/2obg7hKwm5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17834</th>\n",
       "      <td>RT @UTEMISUTS: Decentralizing businesses reputation enables Latin American companies that have never met each other to conduct internationa…</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                       Tweet  \\\n",
       "0               RT @ALXTOKEN: Paul Krugman, Nobel Luddite. I had to tweak the nose of this Bitcoin enemy. He says such foolish things. Here's the link: htt…   \n",
       "1                  @lopp @_Kevin_Pham @psycho_sage @naval But @ProfFaustus (dum b a ss) said you know nothing about #Bitcoin ... 😂😂😂 https://t.co/SBAMFQ2Yiy   \n",
       "2               RT @tippereconomy: Another use case for #blockchain and #Tipper. The #TipperEconomy  can unseat Facebook and change everything! ICO Live No…   \n",
       "3                                                                                                                         free coins https://t.co/DiuoePJdap   \n",
       "4      RT @payvxofficial: WE are happy to announce that PayVX Presale Phase 1 is now LIVE!\\n\\nSign up --&gt;&gt; https://t.co/dhprzsSxek\\nCurrencies accept…   \n",
       "...                                                                                                                                                      ...   \n",
       "17830           RT @PumaPay: Why Did Credit Cards Fail to Adopt to the Modern Needs? https://t.co/u1qB3gxA3T #pumapay #creditcards #banking #finance #block…   \n",
       "17831                                             Bitcoin Will Be World's 'Single Currency' Says Twitter CEO https://t.co/f4hsEbLgkk https://t.co/P3fuHSLwkX   \n",
       "17832        RT @CloudMiningX: Use the code: HF18BDAY30 at purchase to get a 30% discount for all contracts. The offer is limited. \\n\\n10 Ghs = 0.84$\\n1000…   \n",
       "17833                                                     Twitter CEO Says Bitcoin Will Be World’s ‘Single Currency’ Within A Decade https://t.co/2obg7hKwm5   \n",
       "17834           RT @UTEMISUTS: Decentralizing businesses reputation enables Latin American companies that have never met each other to conduct internationa…   \n",
       "\n",
       "      Sentiment  \n",
       "0       neutral  \n",
       "1       neutral  \n",
       "2      positive  \n",
       "3      positive  \n",
       "4      positive  \n",
       "...         ...  \n",
       "17830  negative  \n",
       "17831  negative  \n",
       "17832  negative  \n",
       "17833  negative  \n",
       "17834  negative  \n",
       "\n",
       "[17835 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF = pd.DataFrame(columns=[\"Tweet\", \"Sentiment\"])\n",
    "\n",
    "positiveCount = 0\n",
    "neutralCount = 0\n",
    "\n",
    "for index, row in btc_tweets.iterrows():\n",
    "    sentiment = btc_tweets['Sentiment'][index]\n",
    "    \n",
    "    if sentiment == \"positive\":\n",
    "        if positiveCount == negativeCount:\n",
    "            continue\n",
    "        positiveCount += 1\n",
    "        newDF.loc[len(newDF)]=[row[\"Tweet\"], row[\"Sentiment\"]] \n",
    "        \n",
    "    if sentiment == \"neutral\":\n",
    "        if neutralCount == negativeCount:\n",
    "            continue\n",
    "        neutralCount += 1\n",
    "        newDF.loc[len(newDF)]=[row[\"Tweet\"], row[\"Sentiment\"]] \n",
    "        \n",
    "    if sentiment == \"negative\":\n",
    "        newDF.loc[len(newDF)]=[row[\"Tweet\"], row[\"Sentiment\"]] \n",
    "        \n",
    "newDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Balance Again\n",
    "\n",
    "Balancing the tweets has reduced our dataset to 17,834 instances. We will check balance again now after balancing the sentiments with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Tweets: 5945\n",
      "Neutral Tweets: 5945\n",
      "Negative Tweets: 5945\n"
     ]
    }
   ],
   "source": [
    "btc_tweets = newDF\n",
    "\n",
    "positiveCount = 0\n",
    "neutralCount = 0\n",
    "negativeCount = 0\n",
    "\n",
    "for index, row in btc_tweets.iterrows():\n",
    "    sentiment = btc_tweets['Sentiment'][index].strip('][\\'')\n",
    "    \n",
    "    if sentiment == \"positive\":\n",
    "        positiveCount += 1\n",
    "        \n",
    "    if sentiment == \"neutral\":\n",
    "        neutralCount += 1\n",
    "        \n",
    "    if sentiment == \"negative\":\n",
    "        negativeCount += 1\n",
    "        \n",
    "print(\"Positive Tweets:\", positiveCount)\n",
    "print(\"Neutral Tweets:\", neutralCount)\n",
    "print(\"Negative Tweets:\", negativeCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is Balanced\n",
    "\n",
    "The data has successfully been balanced and now we have 5,945 instances of each sentiment in the dataset. Now we can proceed to split between training and testing data.\n",
    "\n",
    "The following code block will do this:\n",
    "\n",
    " - First, separate dataframes with both all columns will be made with 80% training data and 20% testing data. This data will be saved as .csv files.\n",
    " - Then, the original data will be split again. Now we need to separate with 80 - 20% difference as well separate the columns. This is crucial in the code to follow after this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 14268\n",
      "Number of testing instances: 3567\n"
     ]
    }
   ],
   "source": [
    "# Creating csv's for presentation purpose\n",
    "train_tosave, test_tosave = train_test_split(btc_tweets, test_size=0.2)\n",
    "\n",
    "train_tosave.to_csv(r'train_set.csv', index = False)\n",
    "test_tosave.to_csv(r'test_set.csv', index = False)\n",
    "\n",
    "# 80% training set, 20% testing set\n",
    "tweets = btc_tweets[\"Tweet\"]\n",
    "sentiments = btc_tweets[\"Sentiment\"]\n",
    "\n",
    "train_data, test_data, train_sentiment, test_sentiment = train_test_split(tweets, sentiments, test_size=0.2)\n",
    "\n",
    "rand_indexs = np.random.randint(1,len(train_data),50).tolist()\n",
    "\n",
    "print(\"Number of training instances:\", len(train_data.index))\n",
    "print(\"Number of testing instances:\", len(test_data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4538      Name: Raiden Network Token\\nSymbol: RDN\\n24 hour change: -4.69%\\nPrice: 1.58653\\nRank: 129\\nTotal Supply: 100000000.0\\nVo… https://t.co/KHrEl2usc2\n",
       "3436                   RT @cryptomsn: Home of Bitcoin Crypto Currency - https://t.co/O0gPKD0Ie8 \\n#BTC #CryptoCurrencyNews #Eth #Ltc https://t.co/76hvwd6DlH\n",
       "8986         RT @OnWindowly: Lightning Network Problems — wow!\\n#BitcoinCash is #Bitcoin\\n\\n@el33th4xor  @ Satoshi Vision Conference in Tokyo, Japan. https…\n",
       "5119             RT @DrDenaGrayson: @ericgeller Agree w/@ericgeller👉🏼likely signals #indictments of state-backed hackers. I believe that these hackers will…\n",
       "17443        RT @CloudMiningX: Use the code: HF18BDAY30 at purchase to get a 30% discount for all contracts. The offer is limited. \\n\\n10 Ghs = 0.84$\\n1000…\n",
       "12025     Name: CRYPTO20\\nSymbol: C20\\n24 hour change: -7.7%\\nPrice: 1.29942\\nRank: 168\\nTotal Supply: 40656082.0\\nVolume: 2603890.… https://t.co/h3G19w0ywl\n",
       "14952                                      Current Bitcoin Rate in USD : 8,414.4538 Check other Currencies: https://t.co/KqQpwIzXrs #BitsRate #BTC #Bitcoins\n",
       "5168     RT @UppercoinC: #Giveaway $100 in $ETH!\\n\\n-Like\\n-Retweet\\n-Follow\\n-Comment down below with your #Ethereum (preferably) ERC20 address.\\n\\nLike a…\n",
       "14985      Name: Metaverse ETP\\nSymbol: ETP\\n24 hour change: -11.43%\\nPrice: 0.895199\\nRank: 217\\nTotal Supply: 57379980.0\\nVolume:… https://t.co/oHYFNZYod2\n",
       "10767            RT @hackinjeebs: @LouiseBagshawe @LoolooMagdalena @patribotics I’m hoping for a bitcoin announcement. Something that references that block…\n",
       "10570           Britain Introduces Crypto Task Force To Foster Fintech Innovation #cryptocurrency #crypto #bitcoin #altcoin #inve... https://t.co/kEaQVJe6PF\n",
       "377                                             ICE Agency Charges Payza and Two Canadian Citizens With Bitcoin Money Laundering #ico #cryptocurrency #token\n",
       "4018                                                                           EBay ‘Seriously Considering’ Adding #Bitcoin Payments https://t.co/7SgygfezrI\n",
       "4755                                                        @CryptoTrendy I conceive you can be a unique bitcoin expert please visit https://t.co/6rortIStnD\n",
       "4789     RT @MsxNetwork: Last day for #AION token holder!\\n\\nCheck ANN thread for more detail \\nhttps://t.co/8Mbvhqbvem\\n\\nDo not miss it!\\n\\n#microstack #…\n",
       "243           RT @OfficialMusards: Our Telegram community is reaching 28k users...\\nWe want to thank you all!\\nNew features and news on our website, coming…\n",
       "5517          RT @PeerMountain: Check out again our video to understand how Peer Mountain works :)\\n\\n#blockchain #cryptocurrency #bitcoin #ethereum #Techn…\n",
       "8409            RT @bethereumteam: Have you seen any of the Animated Motion Pictures that are nominated for the Oscars? Would you bet that you can guess th…\n",
       "1332                                   Tom Lee: “The Altcoin Bear Rally is Almost at an End,” but still Stick to Bitcoin\\nhttps://t.co/sjyoiczwwI\\n$BTC #BTC\n",
       "4442            @zabala_jeric @buzzshownetwork Bitcoin Gold (Bitcoin-Gold) do  gaining popular also apt more expensive, marely Your… https://t.co/0Ayk8TtEfk\n",
       "3248      Name: COSS\\nSymbol: COSS\\n24 hour change: -7.4%\\nPrice: 0.254438\\nRank: 335\\nTotal Supply: 104000000.0\\nVolume: 1023840.0… https://t.co/a2EvYrM2ly\n",
       "5310            RT @bethereumteam: We already have an iOS prototype of the betting process through Bethereum on the AppStore! Are you ready to challenge yo…\n",
       "15900                                                            Bitcoin Loses $9k Support After Binance Confusion Shakes Confidence https://t.co/gwV5C80LUc\n",
       "4588      Name: Asch\\nSymbol: XAS\\n24 hour change: -12.34%\\nPrice: 0.720606\\nRank: 141\\nTotal Supply: 114855331.0\\nVolume: 4978880.… https://t.co/piGLGJ9X92\n",
       "7733       RT @PhotoCoin_io: 2,000,000 PHT TOKEN #airdrop \\n1. Follow \\n2. Like\\n3. Retweet ,tag 5 Friends with #PHT\\n4. Comment your ETH address \\nTotal s…\n",
       "5545            #bitcoin (Coincheck: NEM Foundation Stops Tracing Stolen Coins, Hackers’ Account At Zero) has been published on Bit… https://t.co/ExNb1Pe5To\n",
       "9912            RT @adamludwin: 1/Satoshi said Bitcoin was for “commerce on the internet” (the first four words of the Bitcoin whitepaper). Turns out she w…\n",
       "3435           RT @bethereumteam: Do you remember the last time you had fun while betting?\\nWell, with #Bethereum you will! We're bringing the holy trinity…\n",
       "4159           RT @MinerGate: Why Proof-of-capacity could be the future of #cryptocurrency? The answer you will find in our new blog post:\\n➡️🖊️https://t.c…\n",
       "8887                                  #bitcoin Growing mistrust threatens Facebook after data mining scandal https://t.co/63ARp5eBQO https://t.co/UwuYRYF2V8\n",
       "15916                                                                                                 @aliraja How can you 'predict' when bitcoin goes down?\n",
       "11614         RT @bethereumteam: We're revealing our surprise tomorrow! \\nAre you ready to celebrate with us? 😮\\n#surprise #presents #crypto #bitcoin #ethe…\n",
       "5227          RT @bethereumteam: Checkout an interview with our team!\\nWe feel that interviews get us even closer to our community. 🤝\\nhttps://t.co/AUpyskY…\n",
       "3738         RT @izx_io: #TOKEN2049 is finished💫\\nWe want to thank everybody who supported us in Hong Kong!🙌\\n\\n#izx #izetex #blockchain #VR #AR #vrparks #…\n",
       "13704           RT @XVGDolphin: @WinwithRick We are a crypto community and we stick together, one small step taken by thousands will make Verge known to Mi…\n",
       "15531            RT @PeerMountain: Security requires safeguards that make it difficult or impossible for criminals to gain access to your information. Read…\n",
       "205             #power #SelectionSunday #Cryptopia #CryptoNews #cryptocurency #ICO #Bitcoin #ethereum #blockchaintechnology #Market… https://t.co/8tn2Ouektj\n",
       "1675        Bitcoin (-0.15): $8,716.30\\nEthereum (0.1): $540.09\\nRipple (-0.62): $0.66\\nBitcoin Cash (0.54): $1,017.03\\nLitecoin (-… https://t.co/s2R2uEbCXR\n",
       "3590                                                     I added a video to a @YouTube playlist https://t.co/jRPJqOQsL7 I kissed a Bitcoin and I liked it! 💋\n",
       "5164                                       Earning $100K Mining Bitcoin Ethereum ZCash! – Mining BTC ETH ZEC – CryptoCurrency Mining https://t.co/5G4WDWa4MA\n",
       "4145            RT @bethereumteam: Create custom group bets and invite your friends, choose the buy in amounts, select what sport to bet on and enjoy the g…\n",
       "13721           RT @InvResDynamics: SPX down another 20 points from the close.  10yr yield below 2.80.  Gold is flying.  Bitcoin is tanking.  Markets are r…\n",
       "2064                    Our goal is to be the best cryptocurrency trading platform in the world for traders https://t.co/EOjqDZfjNo… https://t.co/zRICEPeZs0\n",
       "3165       Name: BlockMason Credit Protocol\\nSymbol: BCPT\\n24 hour change: -9.14%\\nPrice: 0.493775\\nRank: 220\\nTotal Supply: 116158… https://t.co/6NZzYxPAyj\n",
       "11996           RT @CoinbayExchange: Giveaway still on!!🎉🎊🎇🎉 Our #Airdrop is worth $1,000,000 and started on 18th March. https://t.co/muULREbL0Z RETWEET an…\n",
       "1704                                                     Researchers Discover Child Pornography Hidden in Bitcoin’s Blockchain  #btc https://t.co/dQtgUu1Qrd\n",
       "13688           @CoinRaffles I'm thinking of putting my current #bitcoin giveaways over to your system because it automates the who… https://t.co/Gir5oAzBcL\n",
       "15690            RT @muirfieldip: \"TAOs... offer enhanced safety for investors and accountability for the issuing firm.\" - Tom Zaccagnino (@tomzaccagnino),…\n",
       "7472      RT @truegameSRL: 🚀 Truegame team is fully ready to conquer Tallinn! ✔️\\n\\nTomorrow we'll be attending Blockchain &amp; Bitcoin Conference Tallinn…\n",
       "8628            RT @Marvel_euphoria: Enough is enough. Chinese govt tell companies who are falsefuly claiming Blockchain affiliation just for the sake of b…\n",
       "15694            RT @PeerMountain: Security requires safeguards that make it difficult or impossible for criminals to gain access to your information. Read…\n",
       "8037           RT @WealthE_Coin: Have you ever had the question “What is Bitcoin?”...check out this video #Bitcoin #Blockchain #WealthMigrate #WealthE \\nht…\n",
       "904                                    Ben is a chatbot that lets you learn about and buy Bitcoin https://t.co/qNp7qNKSfd #CryptocurrencyNews #bitcoin #Bots\n",
       "16511                                    WSJ: #SEC To Examine Up To 100 Crypto-Related Hedge Funds: In the US, the… https://t.co/feQqjx7ffI #bitcoin #crypto\n",
       "16664           I followed this one “crypto guru” as a joke and then every day some other crypto account follows me. This one is my… https://t.co/SCNQvlcn11\n",
       "17467     RT @btccloud: Official Bitcoin Cloud #Airdrop 1\\n\\nhttps://t.co/wyumnhGR49\\n\\nLimited to 10,000 Members\\nTotal Supply # 20M\\n4M Coins Will be Air…\n",
       "10830           RT @bethereumteam: Have you seen any of the Animated Motion Pictures that are nominated for the Oscars? Would you bet that you can guess th…\n",
       "12590           RT @Marvel_euphoria: You know what else makes sense, is making Millions in 💰💰. A spokesperson has announced on Thursday that, the U.S. Mars…\n",
       "7747                       💯 Earn FREE Bitcoin https://t.co/aFMj2a15LU 💰 #BTCPeek #Btc #BitcoinB #BtcSales #BitcoinPh #BitcoinPoker… https://t.co/yxsM08r35V\n",
       "10240                                   RT @thehackfund: Investors bullish on bitcoin now that the 'Tokyo Whale' has stopped selling https://t.co/3ZCULmPqmM\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training data:\")\n",
    "train_data.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12501             #Blockchain simplified: @CBinsights / #crypto #fintech #bitcoin, #ICO https://t.co/WuEnTKIq6r / @BourseetTrading… https://t.co/tuU6Yjy2Vh\n",
       "607      Name: Tidex Token\\nSymbol: TDX\\n24 hour change: -38.18%\\nPrice: 0.312157\\nRank: 647\\nTotal Supply: 10000000.0\\nVolume: 29… https://t.co/UvqZKkplhU\n",
       "13116                 [USD] 23/03/2018 03:00:01 Bitcoin: $8451.49 Ethereum: $516.85  #bitcoin #ethereum #altcoin #coin #blockchain… https://t.co/dZ4Wv0WcS5\n",
       "10555      RT @CherylPreheim: City of Atlanta’s computers being held hostage by hacker demanding $51,000 ransom in bitcoin. FBI &amp; Homeland Security in…\n",
       "15317                 RT @ErikVoorhees: CNBC: Jack Dorsey expects bitcoin to become the world's 'single currency' in about 10 years https://t.co/ERONOX5cH1\n",
       "13995    Name: AdEx\\nSymbol: ADX\\n24 hour change: -8.72%\\nPrice: 0.754066\\nRank: 155\\nTotal Supply: 100000000.0\\nVolume: 6612940.0… https://t.co/ghfLGDKUgr\n",
       "2243                                    Why Blockchain Will Survive Even If Bitcoin Doesn't\\nhttps://t.co/agHTUR7Ur5 #Blockchain #Bitcoin #btc #crypto #p2p\n",
       "13629                 Bitcoin falls after report that one of the biggest crypto exchanges is facing regulatory trouble https://t.co/QlZtzVXhNM via @markets\n",
       "11201            RT @metalpaysme: A study showed that 30% of millennial's would rather invest $1,000 in Bitcoin than $1,000 in government bonds or stocks.…\n",
       "16171       RT @CloudMiningX: Use the code: HF18BDAY30 at purchase to get a 30% discount for all contracts. The offer is limited. \\n\\n10 Ghs = 0.84$\\n1000…\n",
       "13651                         RT @Bitcoin: Jack Dorsey expects bitcoin to become the world's 'single currency' in about 10 years\\n\\nhttps://t.co/V0wy32Fy38\n",
       "13573        RT @bethereumteam: It's been 72 hours since the official launch of our Bounty campaign.\\nIs there a stronger crypto community out there?\\n#cr…\n",
       "366            RT @SteveRichFXCorp: #Breaking #SteveRichFXCorp #News Alert : https://t.co/UUGvxAIMYh is now live! Latest News and Updates on Cryptocurrenc…\n",
       "17346          RT @WorldCoinIndex: #Bitcoin All Set to Replace the U.S #Dollar as World’s Single Currency, Says Twitter co-founder Jack Dorsey https://t.c…\n",
       "5966           RT @ErikVoorhees: Many have questioned how Bitcoin works, and stay away from it due to this uncertainty. Meanwhile, not 1 in 100 of them kn…\n",
       "15509    Name: SunContract\\nSymbol: SNC\\n24 hour change: -4.86%\\nPrice: 0.18774\\nRank: 277\\nTotal Supply: 122707503.0\\nVolume: 465… https://t.co/mZkXYp9Qw2\n",
       "1157           RT @NickSzabo4: In particular, every full node watches every other full node (including watching the miners).  Robots in green eyeshades ti…\n",
       "9961          RT @egamexofficial: our community in the telegram  https://t.co/2S0DGb5fko \\n#egamex #egamexcoin #swap #bitcoin #litecoin #yobit @CoinExchan…\n",
       "9296     RT @LitePalOfficial: #Bitcoin &amp; #Litecoin\\n\\nFor far too long have we assigned a value to the worthless paper we're told has worth, now we en…\n",
       "17259    Name: COSS\\nSymbol: COSS\\n24 hour change: -10.91%\\nPrice: 0.243701\\nRank: 336\\nTotal Supply: 104000000.0\\nVolume: 1056420… https://t.co/yHPYFm6nrQ\n",
       "7870                          Great, easy to use platform,best bounty company \\nC clear interface and a good reward.\\n@WealthE_Coin https://t.co/6vK6tGmryR\n",
       "465            RT @SmartTaylorApp: Buy pressure: China and the USA are forbidden to buy TAY until after the token sale. What do you think it will hapen th…\n",
       "5586     RT @AivarasTop: Binance Just Open Registrations. Hurry! 🚀\\n\\n➡️ https://t.co/22NwNrwmyM        \\n\\nSign up here to receive 20$ free coin 💰\\n\\n$BT…\n",
       "3166       RT @RandolphMlny: #Bitcoin #cryptocurrency  #Airdrop\\nNew Airdrop #Tron 📢\\n\\nHuobi Exchange Airdrop 80 TRON (#TRX) to grow their user base!\\nEa…\n",
       "7455               [TR] 23/03/2018 01:59:02 Bitcoin: ₺34416 Ethereum: ₺2137  #bitcoin #ethereum #altcoin #coin #blockchain #crypto… https://t.co/0lgiTl5ulH\n",
       "7553                                      Current Bitcoin Rate in USD : 8,608.7650 Check other Currencies: https://t.co/KqQpwIzXrs #BitsRate #BTC #Bitcoins\n",
       "7958           RT @RC_Mining: Forecast algorithm has detected that #BtcZ is a fantastic #investment📈🚀https://t.co/6Ood8V3zyw @BitcoinZTeam  @RealTimeCrypt…\n",
       "16147                                                                Monthly Web Traffic for Major #bitcoin Exchanges Falls by Half https://t.co/ffX48OxiKE\n",
       "10047          RT @maxkeiser: This also applies to Myron Scholes new ‘stable crypto coin’. || Centralized State Digital Tokens ‘Can’t Compete With Bitcoin…\n",
       "3731         RT @bethereumteam: We're revealing our surprise tomorrow! \\nAre you ready to celebrate with us? 😮\\n#surprise #presents #crypto #bitcoin #ethe…\n",
       "5405                 RT @alexposadzki: TMX enters bitcoin market with new cryptocurrency platform @willis_andrew /via @globeandmail https://t.co/KzDpZR4E80\n",
       "15338        RT @TubiPlatform: \"bitcoin is the future currency. It's what we will all be using.\"\\n\\nTim Draper who previously predicted that BTC would hit…\n",
       "9392                                         #spentenoughmoneytoday How much money can bitcoin miners make? https://t.co/c0auOFILBj https://t.co/p8uMdZukVf\n",
       "8789                  i earn $2000 weekly click here to subscribe and find out how http://airdrop_er20\\n#crypto #altcoin #dogecoin… https://t.co/YvFTy3JqPa\n",
       "3414                  Here Are 7 Crypto Comparison Sites Chasing Coinmarketcap’s Crown - https://t.co/sHByHF4Vz0 - Generate Bitcoin. Take your free Bitcoin\n",
       "14675          RT @FreeZone_one: Privacy-focused cryptocurrency zcash is gearing up for its first hard fork. #cryptocurrency #investment #investing #crypt…\n",
       "5618         RT @AnselLindner: There's been more SW txs than #bcash txs.\\n\\nAfter the 2 year blocksize conflict, where we were told by FUDsters that 'we m…\n",
       "6503                 RT @Applancer_pro: Why Blockchain Will Survive Even If Bitcoin Doesn't\\nhttps://t.co/chtRI5PCyB #Blockchain #Bitcoin #btc #crypto #p2p\n",
       "7888           #Bitcoin value in the next 2 days should be somewhere about 💰 $8,735.52.\\n📈 Gain: $112.26\\n📈 Gain percentage: 1.30%… https://t.co/63hHxCjkki\n",
       "15297                                                           Bitcoin News: With the New Casa Bitcoin Cold Storage Wallet Hack... https://t.co/yU8CwD8gWh\n",
       "13790                               RT @BTCTN: Crypto Collectibles Are Worthless Without a Website https://t.co/XpfAkSSF7j #Bitcoin https://t.co/3H0aT2v0lV\n",
       "10942                                 The Future Of Bitcoin, From A Finance Perspective https://t.co/ALEvkVWnFF #bitcoin #ethereum #btc #crypto #blockchain\n",
       "15582                                                                               Bitcoin ‘could become illegal’ https://t.co/K0XMIYxKlo via @newscomauHQ\n",
       "4249         RT @bethereumteam: Our transparent and easy-to-use bounty solution is almost ready for a live launch!\\n\\nJoin our community on Telegram: http…\n",
       "13181    Name: Asch\\nSymbol: XAS\\n24 hour change: -27.15%\\nPrice: 0.569067\\nRank: 160\\nTotal Supply: 114855331.0\\nVolume: 3411400.… https://t.co/5rNf3axNRi\n",
       "1910       @PinoyGameStore Bitcoin Gold (BTG) and become popular &amp; right extra expensive, marely Your still donТt hold it? You… https://t.co/LSLGQ9W0KE\n",
       "187                              CRYPTOLOANS ICO FIRST BLOCKCHAIN PLATFORM FOR SECURE LENDING\\nTRADING AND EXCHANGE CRYPTOCURRENCY… https://t.co/hQ2hQqW5jw\n",
       "4761                                                       RT @Gamblica: We need our own #crypto Groundhog Day for things like that https://t.co/K84cRqjQdZ\n",
       "744         RT @BuzToken: Airdrop 5000 people can get $10,00,000 worth of buzz\\nCrowdsale price is $0.12\\n✔️ Like and follow \\n✔️ Retweet. Tag 5 your frie…\n",
       "8651           RT @bethereumteam: After a successful launch of our Bounty campaign, we've managed to filter out the Bounty related questions to: https://t…\n",
       "7952           (The Australian dollar tanked) has been published on Free Forex Signals - Forex/ Bitcoin Signals Service - Manage A… https://t.co/DkKmtlNg2C\n",
       "4564        RT @bethereumteam: The Bether #token.\\nSimple, #safe, #transparent and socially engaging!\\nLearn more: https://t.co/C5UxE6TPGJ\\n#crypto #block…\n",
       "10771          RT @Blockchainlife: There is now $1.000.000 of US debt for every #Bitcoin that will ever be mined. At $21 trillion, the national debt is gr…\n",
       "3249           RT @GymRewards: https://t.co/Bm9sIxiiwU  Checkout our #bitcointalk #ANN https://t.co/J5xnJJr7Sa … #Gymrewards #tokenssale #ethereum #bitcoi…\n",
       "3871            RT @DomusCoins: Transfers are regulated automatically by Smart Contracts which are electronic rules, published on the blockchain, that are…\n",
       "15874                                                           Bitcoin Loses $9k Support After Binance Confusion Shakes Confidence https://t.co/crXsJKWe2K\n",
       "14767          RT @MAVRO_COIN: The ICO will be closed before you know it! Get your tokens now! #Mavro #cryptocurrency #blockchain #crypto #bitcoin #bitcoi…\n",
       "14662                                    #EOS Price is 0.00079152 (+0.00000808) #BTC / 6.68708 (+0.11217) #USD. Market rank is 7. #eos #bitcoin #blockchain\n",
       "7222                              @Just_Hash_Me @YoustockProject @YouStockAura This article explains a little about what I’m doing\\nhttps://t.co/lpvM7Uc8ky\n",
       "3236                                                                                   How to Kill Bitcoin? https://t.co/7pqUFTyBUH https://t.co/yMaUEHqfLL\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing data:\")\n",
    "test_data.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value of Emoticons as Sentiment\n",
    "\n",
    "Emoticons are extremely important for sentiment analysis as they are clear exressors of emotions. The following code matches all emojis in our training dataset that match with a specific regular expression that is designed to generate all emojis.\n",
    "\n",
    "This step is only for presentation purposes. These values will not actually be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoticons used in dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(14363, ': '),\n",
       " (115, ':…'),\n",
       " (39, 'XM'),\n",
       " (36, ':)'),\n",
       " (7, ':('),\n",
       " (2, ';)'),\n",
       " (2, ':D')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking which emoticons are used in data set\n",
    "tweets_text = train_data.str.cat()\n",
    "\n",
    "emos = set(re.findall(r\" ([xX:;][-']?.) \", tweets_text))\n",
    "emos_count = []\n",
    "for emo in emos:\n",
    "    emos_count.append((tweets_text.count(emo), emo))\n",
    "print(\"Emoticons used in dataset:\")\n",
    "sorted(emos_count,reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoticons in Our Dataset by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoticons specifying happy and sad expressions:\n",
      "\n",
      "Happy emoticons used: {';)', ':D', ':)'}\n",
      "Sad emoticons used: {':('}\n"
     ]
    }
   ],
   "source": [
    "# Checking frequency of happy and sad emoji encounters\n",
    "\n",
    "HAPPY_EMO = r\" ([xX;:]-?[dD)]|:-?[\\)]|[;:][pP]) \"\n",
    "SAD_EMO = r\" (:'?[/|\\(]) \"\n",
    "\n",
    "print(\"Emoticons specifying happy and sad expressions:\\n\")\n",
    "\n",
    "print(\"Happy emoticons used:\", set(re.findall(HAPPY_EMO, tweets_text)))\n",
    "print(\"Sad emoticons used:\", set(re.findall(SAD_EMO, tweets_text)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Used Words\n",
    "\n",
    "The following function will check for most used words in our dataset so we have a clear visual of what we're working with. The nltk library will first download a set of words and then check the dataset for most used words before printing them for presentation and clearing purposes.\n",
    "\n",
    "This step is only for presentation purposes. These values will not actually be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zozu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 30513 different words in training dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " '#',\n",
       " 'https',\n",
       " '@',\n",
       " 'Bitcoin',\n",
       " '.',\n",
       " 'the',\n",
       " 'to',\n",
       " ',',\n",
       " '!',\n",
       " '$',\n",
       " 'a',\n",
       " 'is',\n",
       " 'bitcoin',\n",
       " 'and',\n",
       " 'of',\n",
       " 'in',\n",
       " 'for',\n",
       " 'you',\n",
       " '?',\n",
       " 'on',\n",
       " 'Airdrop',\n",
       " '(',\n",
       " ')',\n",
       " '’',\n",
       " '%',\n",
       " 'with',\n",
       " 'that',\n",
       " 'I',\n",
       " '-',\n",
       " 'cryptocurrency',\n",
       " 'bethereumteam',\n",
       " 'our',\n",
       " 'blockchain',\n",
       " 'crypto',\n",
       " 'we',\n",
       " \"'s\",\n",
       " 'Price',\n",
       " 'The',\n",
       " 'your',\n",
       " 'will',\n",
       " 'Supply',\n",
       " 'Total',\n",
       " 'be',\n",
       " '1',\n",
       " 'it',\n",
       " '24',\n",
       " 'are',\n",
       " 'change',\n",
       " 'hour',\n",
       " 's',\n",
       " ';',\n",
       " 'out',\n",
       " 'BTC',\n",
       " 'Symbol',\n",
       " 'at',\n",
       " 'Rank',\n",
       " \"'re\",\n",
       " 'We',\n",
       " '...',\n",
       " 'have',\n",
       " 'by',\n",
       " '&',\n",
       " 'Volume',\n",
       " 'this',\n",
       " 'Blockchain',\n",
       " 'what',\n",
       " 'about',\n",
       " \"''\",\n",
       " '--',\n",
       " '*',\n",
       " 'Ethereum',\n",
       " 'Will',\n",
       " 'can',\n",
       " '``',\n",
       " 'New',\n",
       " 'Twitter',\n",
       " 'has',\n",
       " 'from',\n",
       " '📢',\n",
       " 'ICO',\n",
       " 'Satoshi',\n",
       " 'amp',\n",
       " 'make',\n",
       " '“',\n",
       " 'all',\n",
       " '”',\n",
       " 'article',\n",
       " 'Crypto',\n",
       " 'how',\n",
       " 'or',\n",
       " 'as',\n",
       " '…',\n",
       " 'ethereum',\n",
       " 'not',\n",
       " 'now',\n",
       " 'A',\n",
       " \"'\",\n",
       " 'ETH',\n",
       " 'money']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def most_used_words(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    frequency_dist = nltk.FreqDist(tokens)\n",
    "    print(\"There is %d different words in training dataset\" % len(set(tokens)))\n",
    "    return sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)\n",
    "\n",
    "most_used_words(train_data.str.cat())[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction, defining Vectorizer and Pipeline\n",
    "\n",
    "This is the most important step. For natural language processing, we cannot feed raw text data to models. We have to convert them into a machine understandable format. Here is where our vectorizer will come in.\n",
    "\n",
    "For the purpose of this project, we are using Bag of Words and TF-IDF feature extraction method. The way it works is the it creates a table with each tweet in our dataset as a row, and each column being each word encountered in the dataset atleast once. The tweets per row will then have numerical values with respect to columns to demonstrate the number of said words encountered in the tweet.\n",
    "\n",
    "This simple diagram eases the concept:\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/BoWBag-of-Words-model-2.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "We will use the TfidfVectorizer() from scikit-learn library and make a vectorizer of our own. In the same directory as this .ipynb file, there should be a utils.py file alongside. In said file, a lemmetizer function and an text preprocessing class have been defined which we are using in the code block below.\n",
    "\n",
    "The reason for putting them separately was so that the pickled pipeline works with them later when they're deployed to a Heroku server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data ready to be passed to the model:\n",
      "  (0, 11436)\t0.20075486694643815\n",
      "  (0, 55414)\t0.10031328191932584\n",
      "  (0, 6107)\t0.19068189100977978\n",
      "  (0, 11857)\t0.19068189100977978\n",
      "  (0, 6553)\t0.2452675750855544\n",
      "  (0, 12050)\t0.2452675750855544\n",
      "  (0, 49429)\t0.09740334370414654\n",
      "  (0, 1171)\t0.10024074751618044\n",
      "  (0, 8589)\t0.2452675750855544\n",
      "  (0, 12675)\t0.2452675750855544\n",
      "  (0, 25698)\t0.10013234145865559\n",
      "  (0, 37269)\t0.10024074751618044\n",
      "  (0, 50499)\t0.1815464986234954\n",
      "  (0, 13866)\t0.1815464986234954\n",
      "  (0, 59557)\t0.1542536565856081\n",
      "  (0, 45080)\t0.16530099330427037\n",
      "  (0, 50342)\t0.1815464986234954\n",
      "  (0, 13861)\t0.1815464986234954\n",
      "  (0, 44817)\t0.10020455957761988\n",
      "  (0, 5257)\t0.20075486694643815\n",
      "  (0, 55408)\t0.09408198338361679\n",
      "  (0, 6106)\t0.19068189100977978\n",
      "  (0, 6552)\t0.2452675750855544\n",
      "  (0, 49422)\t0.08723363948657727\n",
      "  (0, 1110)\t0.08896602587879256\n",
      "  :\t:\n",
      "  (14267, 27298)\t0.18985952615516027\n",
      "  (14267, 65890)\t0.18985952615516027\n",
      "  (14267, 342)\t0.18985952615516027\n",
      "  (14267, 21835)\t0.17868324112355058\n",
      "  (14267, 20258)\t0.18985952615516027\n",
      "  (14267, 59856)\t0.18985952615516027\n",
      "  (14267, 55290)\t0.18985952615516027\n",
      "  (14267, 27300)\t0.18985952615516027\n",
      "  (14267, 65624)\t0.18788309633948375\n",
      "  (14267, 30059)\t0.18985952615516027\n",
      "  (14267, 65889)\t0.18985952615516027\n",
      "  (14267, 20255)\t0.18841140320473038\n",
      "  (14267, 27297)\t0.37898394501169186\n",
      "  (14267, 55284)\t0.18268505456046782\n",
      "  (14267, 1254)\t0.1603501729747892\n",
      "  (14267, 16025)\t0.15536279755951415\n",
      "  (14267, 59850)\t0.18617628963833194\n",
      "  (14267, 30141)\t0.1670138377116816\n",
      "  (14267, 30095)\t0.14957756213493043\n",
      "  (14267, 14249)\t0.11706683588032979\n",
      "  (14267, 64316)\t0.11641852573705856\n",
      "  (14267, 63407)\t0.16557828529244598\n",
      "  (14267, 63373)\t0.12002016518689004\n",
      "  (14267, 0)\t0.09289969551699381\n",
      "  (14267, 21834)\t0.056568206781440866\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=utils.lemmatize_tokenize, ngram_range=(1,2))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('text_pre_processing', utils.TextPreProc(use_mention=True)),\n",
    "    ('vectorizer', vectorizer),\n",
    "])\n",
    "\n",
    "training_data = pipeline.fit_transform(train_data)\n",
    "\n",
    "joblib.dump(pipeline, 'pipeline.pkl')\n",
    "\n",
    "print(\"Processed data ready to be passed to the model:\")\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "The above data is the data that was transformed by passing through our defined pipeline according to our lemmetizer and text preprocessing rules class. This will work fine when passed into a model.\n",
    "\n",
    "We will now retain the performance and accuracy of 9 machine learning algorithms on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Classifier ===\n",
      "scores =  [0.90749825 0.9159075  0.91065172 0.91342447 0.90606379]\n",
      "mean =  0.9107091442367186\n",
      "variance =  1.3257659739066788e-05\n",
      "score on the learning data (accuracy) =  1.0\n",
      "\n",
      "\n",
      "=== Perceptron ===\n",
      "scores =  [0.92676945 0.93622985 0.93587947 0.93901157 0.93340343]\n",
      "mean =  0.9342587536791698\n",
      "variance =  1.7184494186189898e-05\n",
      "score on the learning data (accuracy) =  1.0\n",
      "\n",
      "\n",
      "=== Bernoulli Naive Bayes ===\n",
      "scores =  [0.88367204 0.90049054 0.89313245 0.90536278 0.88818787]\n",
      "mean =  0.8941691345934437\n",
      "variance =  6.245940032019872e-05\n",
      "score on the learning data (accuracy) =  0.9718951499859826\n",
      "\n",
      "\n",
      "=== Multinomial Naive Bayes ===\n",
      "scores =  [0.88156973 0.88822705 0.88367204 0.89730109 0.88958991]\n",
      "mean =  0.8880719615271155\n",
      "variance =  2.9828665773171636e-05\n",
      "score on the learning data (accuracy) =  0.9670591533501542\n",
      "\n",
      "\n",
      "=== Complement Naive Bayes ===\n",
      "scores =  [0.88717589 0.89698669 0.8917309  0.90851735 0.89309499]\n",
      "mean =  0.8955011641442109\n",
      "variance =  5.218850994221847e-05\n",
      "score on the learning data (accuracy) =  0.9748388001121391\n",
      "\n",
      "\n",
      "=== Decision Tree Classifier ===\n",
      "scores =  [0.88997898 0.89978977 0.89138052 0.88608482 0.87767263]\n",
      "mean =  0.888981342498129\n",
      "variance =  5.197006157597027e-05\n",
      "score on the learning data (accuracy) =  1.0\n",
      "\n",
      "\n",
      "=== Linear Support Vector Classification ===\n",
      "scores =  [0.9278206  0.93482831 0.9351787  0.94356817 0.92534175]\n",
      "mean =  0.9333475059509029\n",
      "variance =  4.0929391057163947e-05\n",
      "score on the learning data (accuracy) =  0.9999299130922343\n",
      "\n",
      "\n",
      "=== Stochastic Gradient Descent ===\n",
      "scores =  [0.92186405 0.9302733  0.92992292 0.9404136  0.92393971]\n",
      "mean =  0.9292827157191523\n",
      "variance =  4.177439385731084e-05\n",
      "score on the learning data (accuracy) =  0.9954443509952341\n",
      "\n",
      "\n",
      "=== Logistic Regression ===\n",
      "scores =  [0.90504555 0.91520673 0.90889979 0.92393971 0.91132142]\n",
      "mean =  0.9128826391821049\n",
      "variance =  4.1476146110314495e-05\n",
      "score on the learning data (accuracy) =  0.9889262685730306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "cnb = ComplementNB()\n",
    "tree = DecisionTreeClassifier()\n",
    "lsvc = LinearSVC()\n",
    "sgdc = SGDClassifier()\n",
    "randFor = RandomForestClassifier()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest Classifier\": randFor,\n",
    "    \"Perceptron\": perceptron,\n",
    "    \"Bernoulli Naive Bayes\": bnb,\n",
    "    \"Multinomial Naive Bayes\": mnb,\n",
    "    \"Complement Naive Bayes\": cnb,\n",
    "    \"Decision Tree Classifier\": tree,\n",
    "    \"Linear Support Vector Classification\": lsvc,\n",
    "    \"Stochastic Gradient Descent\": sgdc,\n",
    "    \"Logistic Regression\": lr,\n",
    "}\n",
    "\n",
    "\n",
    "for model in models.keys():\n",
    "    scores = cross_val_score(models[model], training_data, train_sentiment)\n",
    "    print(\"\\n===\", model, \"===\")\n",
    "    print(\"scores = \", scores)\n",
    "    print(\"mean = \", scores.mean())\n",
    "    print(\"variance = \", scores.var())\n",
    "    models[model].fit(training_data, train_sentiment)\n",
    "    acc_score = accuracy_score(models[model].predict(training_data), train_sentiment)\n",
    "    print(\"score on the learning data (accuracy) = \", acc_score)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy on Test Data\n",
    "\n",
    "We will now test the accuracy of each model on test data and check which one gives the highest result. As is visible from below, Linear Support Vector Classification gives the highest rating with respect to accuracy for testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data for Random Forest Classifier: 0.913372582001682\n",
      "Accuracy on test data for Perceptron: 0.9425287356321839\n",
      "Accuracy on test data for Bernoulli Naive Bayes: 0.8982338099243061\n",
      "Accuracy on test data for Multinomial Naive Bayes: 0.8901037286234932\n",
      "Accuracy on test data for Complement Naive Bayes: 0.895991028875806\n",
      "Accuracy on test data for Decision Tree Classifier: 0.8873002523128679\n",
      "Accuracy on test data for Linear Support Vector Classification: 0.9428090832632464\n",
      "Accuracy on test data for Stochastic Gradient Descent: 0.9408466498458088\n",
      "Accuracy on test data for Logistic Regression: 0.927950658816933\n"
     ]
    }
   ],
   "source": [
    "# We now test each model on trainset\n",
    "for model in models.keys():\n",
    "    test_model = models[model]\n",
    "    test_model.fit(training_data, train_sentiment)\n",
    "\n",
    "    testing_data = pipeline.transform(test_data)\n",
    "    print(\"Accuracy on test data for \" + model + \":\", test_model.score(testing_data, test_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Test Sentiments to Predictions\n",
    "\n",
    "The time has come to compare test dataset sentiments with our predictions from the model. In the display as follows, both the original sentiment and predicted sentiments are compared side by side. As you can see, the result is quite impressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13116</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13629</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11201</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13651</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13573</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17346</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17259</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16147</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15338</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9392</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14675</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10942</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15582</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13181</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14767</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14662</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment Predicted Sentiment\n",
       "12501   neutral             neutral\n",
       "607    negative            negative\n",
       "13116   neutral             neutral\n",
       "10555   neutral             neutral\n",
       "15317  negative            negative\n",
       "13995  negative            negative\n",
       "2243    neutral             neutral\n",
       "13629  negative            negative\n",
       "11201   neutral             neutral\n",
       "16171  negative            negative\n",
       "13651  negative            negative\n",
       "13573   neutral             neutral\n",
       "366    positive            positive\n",
       "17346  negative            negative\n",
       "5966   positive            positive\n",
       "15509  negative            negative\n",
       "1157   positive            positive\n",
       "9961    neutral             neutral\n",
       "9296   negative            negative\n",
       "17259  negative            negative\n",
       "7870   positive            positive\n",
       "465     neutral             neutral\n",
       "5586   positive            positive\n",
       "3166   negative            negative\n",
       "7455    neutral             neutral\n",
       "7553   negative            negative\n",
       "7958   positive            positive\n",
       "16147  negative            negative\n",
       "10047  positive            positive\n",
       "3731   positive            positive\n",
       "5405   positive            positive\n",
       "15338  negative            negative\n",
       "9392   positive            positive\n",
       "8789    neutral             neutral\n",
       "3414   positive            positive\n",
       "14675  negative            negative\n",
       "5618   positive            positive\n",
       "6503    neutral             neutral\n",
       "7888    neutral             neutral\n",
       "15297  negative            positive\n",
       "13790  negative            negative\n",
       "10942   neutral             neutral\n",
       "15582  negative            negative\n",
       "4249   positive            positive\n",
       "13181  negative            negative\n",
       "1910   positive            positive\n",
       "187    positive            positive\n",
       "4761   positive            positive\n",
       "744    positive            positive\n",
       "8651   positive            positive\n",
       "7952   positive            positive\n",
       "4564   positive            positive\n",
       "10771   neutral             neutral\n",
       "3249    neutral             neutral\n",
       "3871   positive            positive\n",
       "15874  negative            negative\n",
       "14767  negative            negative\n",
       "14662  negative            negative\n",
       "7222   negative            negative\n",
       "3236    neutral             neutral"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose Linear Support Vector Classification due to highest accuracy\n",
    "test_model = lsvc\n",
    "test_learning = pipeline.transform(test_data)\n",
    "\n",
    "tempDF = pd.DataFrame(test_sentiment)\n",
    "tempDF[\"Predicted Sentiment\"] = test_model.predict(test_learning)\n",
    "\n",
    "tempDF.head(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Custom Input\n",
    "\n",
    "We will now test our own input to test the model. As you can see, both the predictions are on point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate bitcoin\n",
      "This tweet is negative\n"
     ]
    }
   ],
   "source": [
    "tweet = pd.Series([input(),])\n",
    "tweet = pipeline.transform(tweet)\n",
    "\n",
    "sentiment_predicted = model.predict(tweet)[0]\n",
    "\n",
    "print(\"This tweet is\", sentiment_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love bitcoin\n",
      "This tweet is positive\n"
     ]
    }
   ],
   "source": [
    "tweet = pd.Series([input(),])\n",
    "tweet = pipeline.transform(tweet)\n",
    "\n",
    "sentiment_predicted = model.predict(tweet)[0]\n",
    "\n",
    "print(\"This tweet is\", sentiment_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "We now save the model as a pickle file so we can use it to deploy on a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open(\"model.pkl\", 'wb'))\n",
    "print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
